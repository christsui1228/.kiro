# ç¯å¢ƒå˜é‡ç®¡ç†è§„èŒƒ

## é…ç½®ç®¡ç†ç­–ç•¥

### ç¯å¢ƒæ–‡ä»¶ä¼˜å…ˆçº§
åŸºäº OneManage çš„é…ç½®è®¾è®¡ï¼Œé‡‡ç”¨åˆ†å±‚ç¯å¢ƒå˜é‡ç®¡ç†ï¼š

```
ç³»ç»Ÿç¯å¢ƒå˜é‡ > .env.{ENV} > .env > é»˜è®¤å€¼
```

### ç¯å¢ƒæ–‡ä»¶å‘½åè§„èŒƒ
- **å¼€å‘ç¯å¢ƒ**: `.env.development` (é»˜è®¤)
- **æµ‹è¯•ç¯å¢ƒ**: `.env.testing`
- **ç”Ÿäº§ç¯å¢ƒ**: `.env.production`
- **é€šç”¨é…ç½®**: `.env` (å…œåº•é…ç½®)
- **é…ç½®æ¨¡æ¿**: `.env.example` (ç‰ˆæœ¬æ§åˆ¶)

### ç¯å¢ƒå˜é‡æ§åˆ¶
```bash
# é€šè¿‡ ENV ç¯å¢ƒå˜é‡æ§åˆ¶åŠ è½½å“ªä¸ªé…ç½®æ–‡ä»¶
ENV=development  # åŠ è½½ .env.development
ENV=production   # åŠ è½½ .env.production
ENV=testing      # åŠ è½½ .env.testing
```

## Pydantic Settings é…ç½®è§„èŒƒ

### é…ç½®ç±»è®¾è®¡ï¼ˆåµŒå¥—ç»“æ„ï¼‰

#### 1. åŸºç¡€é…ç½®å’Œæšä¸¾
```python
from pydantic import BaseModel, Field
from pydantic_settings import BaseSettings, SettingsConfigDict
from functools import lru_cache
from pathlib import Path
import os
from enum import Enum

ROOT_DIR = Path(__file__).resolve().parent.parent

class Environment(str, Enum):
    """ç¯å¢ƒç±»å‹æšä¸¾"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    PRODUCTION = "production"
```

#### 2. åµŒå¥—é…ç½®ç±»
```python
class DatabaseConfig(BaseModel):
    """æ•°æ®åº“é…ç½®"""
    user: str = Field(..., description="æ•°æ®åº“ç”¨æˆ·å")
    password: str = Field(..., description="æ•°æ®åº“å¯†ç ")
    host: str = Field(default="localhost", description="æ•°æ®åº“ä¸»æœºåœ°å€")
    port: int = Field(default=5432, description="æ•°æ®åº“ç«¯å£")
    name: str = Field(..., description="æ•°æ®åº“åç§°")
    echo_log: bool = Field(default=False, description="æ˜¯å¦æ‰“å° SQL æ—¥å¿—")
    
    # è¿æ¥æ± é…ç½®
    pool_size: int = Field(default=10, description="è¿æ¥æ± å¤§å°")
    max_overflow: int = Field(default=20, description="è¿æ¥æ± æœ€å¤§æº¢å‡º")
    
    @property
    def async_url(self) -> str:
        """å¼‚æ­¥æ•°æ®åº“è¿æ¥ URL"""
        return f"postgresql+asyncpg://{self.user}:{self.password}@{self.host}:{self.port}/{self.name}"
    
    @property
    def sync_url(self) -> str:
        """åŒæ­¥æ•°æ®åº“è¿æ¥ URL"""
        return f"postgresql+psycopg://{self.user}:{self.password}@{self.host}:{self.port}/{self.name}"

class NATSConfig(BaseModel):
    """NATS æ¶ˆæ¯é˜Ÿåˆ—é…ç½®"""
    url: str = Field(
        default="nats://localhost:4222",
        description="NATS æœåŠ¡å™¨åœ°å€",
        validation_alias="NATS_SERVER_URL"  # æ”¯æŒäº‘æ•ˆç¯å¢ƒå˜é‡åˆ«å
    )
    stream: str = Field(default="taskiq", description="JetStream æµåç§°")
    user: str | None = Field(default=None, description="è®¤è¯ç”¨æˆ·å")
    password: str | None = Field(default=None, description="è®¤è¯å¯†ç ")
    
    @property
    def servers(self) -> list[str]:
        """è½¬æ¢ä¸º taskiq-nats éœ€è¦çš„æœåŠ¡å™¨åœ°å€åˆ—è¡¨æ ¼å¼"""
        return [self.url]

class S3Config(BaseModel):
    """S3 å¯¹è±¡å­˜å‚¨é…ç½®"""
    endpoint: str | None = Field(default=None, description="S3 æœåŠ¡ç«¯ç‚¹")
    access_key_id: str | None = Field(default=None, description="è®¿é—®å¯†é’¥ ID")
    secret_access_key: str | None = Field(default=None, description="è®¿é—®å¯†é’¥")
    bucket: str | None = Field(default=None, description="å­˜å‚¨æ¡¶åç§°")
    region: str = Field(default="auto", description="åŒºåŸŸ")

class FileStorageConfig(BaseModel):
    """æ–‡ä»¶å­˜å‚¨é…ç½®"""
    upload_dir: str = Field(default="/data/uploads", description="ä¸Šä¼ æ–‡ä»¶ç›®å½•")
    temp_dir: str = Field(default="/tmp", description="ä¸´æ—¶æ–‡ä»¶ç›®å½•")
    
    @property
    def temp_uploads_dir(self) -> Path:
        """PSDä¸Šä¼ ä¸´æ—¶ç›®å½•"""
        path = Path(self.temp_dir) / "psd_uploads"
        path.mkdir(parents=True, exist_ok=True)
        return path
```

#### 3. ä¸»é…ç½®ç±»
```python
class Settings(BaseSettings):
    """ä¸»é…ç½®ç±»"""
    env: Environment = Field(default=Environment.DEVELOPMENT, description="è¿è¡Œç¯å¢ƒ")
    debug: bool = Field(default=False, description="è°ƒè¯•æ¨¡å¼")
    
    # åµŒå¥—é…ç½®ç»„
    database: DatabaseConfig
    nats: NATSConfig
    s3: S3Config
    file_storage: FileStorageConfig
    
    model_config = SettingsConfigDict(
        env_file=(
            ROOT_DIR / f".env.{os.getenv('ENV', 'development').lower()}",
            ROOT_DIR / ".env"
        ),
        env_file_encoding="utf-8",
        case_sensitive=False,
        extra="allow",
        env_nested_delimiter="__"  # åµŒå¥—é…ç½®ä½¿ç”¨åŒä¸‹åˆ’çº¿åˆ†éš”
    )
```

#### 4. é…ç½®åŠ è½½é€»è¾‘
```python
@lru_cache
def get_settings() -> Settings:
    """è·å–é…ç½®å®ä¾‹ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    try:
        settings_instance = Settings()
        
        # åªåœ¨å¼€å‘ç¯å¢ƒæ‰“å°è¯¦ç»†ä¿¡æ¯
        if settings_instance.env == Environment.DEVELOPMENT:
            logger.info(f"âœ… é…ç½®åŠ è½½æˆåŠŸ: {settings_instance.env.value}")
            logger.info(f"ğŸ—„ï¸  æ•°æ®åº“: {settings_instance.database.host}")
            logger.info(f"ğŸ“¨ NATS: {settings_instance.nats.url}")
        
        return settings_instance
    except Exception as e:
        logger.error(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        raise

settings = get_settings()
```

### ç¯å¢ƒå˜é‡å‘½åè§„èŒƒï¼ˆåµŒå¥—é…ç½®ï¼‰

ä½¿ç”¨åŒä¸‹åˆ’çº¿ `__` åˆ†éš”åµŒå¥—å±‚çº§ï¼š

```bash
# é¡¶å±‚é…ç½®
ENV=development
DEBUG=true

# æ•°æ®åº“é…ç½®ï¼ˆDATABASE__ å‰ç¼€ï¼‰
DATABASE__USER=postgres
DATABASE__PASSWORD=postgres
DATABASE__HOST=localhost
DATABASE__PORT=5432
DATABASE__NAME=onemanage_dev
DATABASE__ECHO_LOG=true

# NATS é…ç½®ï¼ˆNATS__ å‰ç¼€ï¼‰
NATS__URL=nats://localhost:4222
NATS__STREAM=taskiq_dev
NATS__USER=
NATS__PASSWORD=

# S3 é…ç½®ï¼ˆS3__ å‰ç¼€ï¼‰
S3__ENDPOINT=https://oss-cn-hangzhou.aliyuncs.com
S3__ACCESS_KEY_ID=your_key
S3__SECRET_ACCESS_KEY=your_secret
S3__BUCKET=your_bucket

# æ–‡ä»¶å­˜å‚¨é…ç½®ï¼ˆFILE_STORAGE__ å‰ç¼€ï¼‰
FILE_STORAGE__UPLOAD_DIR=/data/uploads
FILE_STORAGE__TEMP_DIR=/tmp
```

## å¼€å‘ç¯å¢ƒé…ç½®

### .env.development ç¤ºä¾‹
```bash
# ==================== æ ¸å¿ƒé…ç½® ====================
# è¿è¡Œç¯å¢ƒ: development, testing, production
ENV=development

# è°ƒè¯•æ¨¡å¼
DEBUG=true


# ==================== æ•°æ®åº“é…ç½® ====================
# PostgreSQL æ•°æ®åº“ç”¨æˆ·å
DATABASE__USER=postgres

# PostgreSQL æ•°æ®åº“å¯†ç 
DATABASE__PASSWORD=postgres

# PostgreSQL æ•°æ®åº“ä¸»æœº
DATABASE__HOST=localhost

# PostgreSQL æ•°æ®åº“ç«¯å£
DATABASE__PORT=5432

# PostgreSQL æ•°æ®åº“åç§°
DATABASE__NAME=onemanage_dev

# æ˜¯å¦æ‰“å° SQL æ—¥å¿—ï¼ˆå¼€å‘ç¯å¢ƒå»ºè®® trueï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®® falseï¼‰
DATABASE__ECHO_LOG=true

# è¿æ¥æ± é…ç½®ï¼ˆå¯é€‰ï¼Œæœ‰é»˜è®¤å€¼ï¼‰
DATABASE__POOL_SIZE=10
DATABASE__MAX_OVERFLOW=20
DATABASE__POOL_RECYCLE=180


# ==================== NATS æ¶ˆæ¯é˜Ÿåˆ—é…ç½® ====================
# NATS æœåŠ¡å™¨åœ°å€
NATS__URL=nats://localhost:4222

# JetStream æµåç§°
NATS__STREAM=taskiq_dev

# NATS è®¤è¯ç”¨æˆ·åï¼ˆå¯é€‰ï¼‰
# NATS__USER=admin

# NATS è®¤è¯å¯†ç ï¼ˆå¯é€‰ï¼‰
# NATS__PASSWORD=your-nats-password


# ==================== S3 å¯¹è±¡å­˜å‚¨é…ç½®ï¼ˆå¯é€‰ï¼‰ ====================
# å¦‚æœä¸éœ€è¦å¯¹è±¡å­˜å‚¨ï¼Œå¯ä»¥æ³¨é‡Šæ‰è¿™éƒ¨åˆ†
# æ”¯æŒé˜¿é‡Œäº‘ OSSã€Cloudflare R2ã€AWS S3ã€MinIO ç­‰

# S3 æœåŠ¡ç«¯ç‚¹
# S3__ENDPOINT=https://oss-cn-hangzhou.aliyuncs.com

# S3 è®¿é—®å¯†é’¥ ID
# S3__ACCESS_KEY_ID=your_access_key

# S3 è®¿é—®å¯†é’¥
# S3__SECRET_ACCESS_KEY=your_secret_key

# S3 å­˜å‚¨æ¡¶åç§°
# S3__BUCKET=your_bucket

# S3 å¯¹è±¡é”®å‰ç¼€ï¼ˆå¯é€‰ï¼‰
# S3__PREFIX=dev

# S3 åŒºåŸŸ
# S3__REGION=auto


# ==================== æ–‡ä»¶å­˜å‚¨é…ç½® ====================
# ä¸Šä¼ æ–‡ä»¶ç›®å½•
FILE_STORAGE__UPLOAD_DIR=/data/uploads

# æŠ¥å‘Šæ–‡ä»¶ç›®å½•
FILE_STORAGE__REPORT_DIR=/data/reports

# ä¸´æ—¶æ–‡ä»¶ç›®å½•
FILE_STORAGE__TEMP_DIR=/tmp


# ==================== ä½¿ç”¨è¯´æ˜ ====================
# 1. å¤åˆ¶æ­¤æ–‡ä»¶ä¸º .env.development
# 2. æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹é…ç½®å€¼
# 3. ä¸éœ€è¦çš„é…ç½®å¯ä»¥æ³¨é‡Šæ‰æˆ–åˆ é™¤
# 4. æ•æ„Ÿä¿¡æ¯ï¼ˆå¯†ç ã€å¯†é’¥ï¼‰ä¸è¦æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶
```

### .env.example æ¨¡æ¿
```bash
# ==================== æ ¸å¿ƒé…ç½® ====================
# è¿è¡Œç¯å¢ƒ: development, testing, production
ENV=development

# è°ƒè¯•æ¨¡å¼
DEBUG=false


# ==================== æ•°æ®åº“é…ç½® ====================
# PostgreSQL æ•°æ®åº“ç”¨æˆ·å
DATABASE__USER=your_db_user

# PostgreSQL æ•°æ®åº“å¯†ç 
DATABASE__PASSWORD=your_db_password

# PostgreSQL æ•°æ®åº“ä¸»æœº
DATABASE__HOST=localhost

# PostgreSQL æ•°æ®åº“ç«¯å£
DATABASE__PORT=5432

# PostgreSQL æ•°æ®åº“åç§°
DATABASE__NAME=your_db_name

# æ˜¯å¦æ‰“å° SQL æ—¥å¿—ï¼ˆå¼€å‘ç¯å¢ƒå»ºè®® trueï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®® falseï¼‰
DATABASE__ECHO_LOG=false

# è¿æ¥æ± é…ç½®ï¼ˆå¯é€‰ï¼Œæœ‰é»˜è®¤å€¼ï¼‰
DATABASE__POOL_SIZE=10
DATABASE__MAX_OVERFLOW=20
DATABASE__POOL_RECYCLE=180


# ==================== NATS æ¶ˆæ¯é˜Ÿåˆ—é…ç½® ====================
# NATS æœåŠ¡å™¨åœ°å€
NATS__URL=nats://localhost:4222

# JetStream æµåç§°
NATS__STREAM=taskiq

# NATS è®¤è¯ç”¨æˆ·åï¼ˆå¯é€‰ï¼‰
# NATS__USER=

# NATS è®¤è¯å¯†ç ï¼ˆå¯é€‰ï¼‰
# NATS__PASSWORD=


# ==================== S3 å¯¹è±¡å­˜å‚¨é…ç½®ï¼ˆå¯é€‰ï¼‰ ====================
# å¦‚æœä¸éœ€è¦å¯¹è±¡å­˜å‚¨ï¼Œå¯ä»¥æ³¨é‡Šæ‰è¿™éƒ¨åˆ†

# S3 æœåŠ¡ç«¯ç‚¹
# é˜¿é‡Œäº‘ OSS: https://oss-cn-hangzhou.aliyuncs.com
# Cloudflare R2: https://<account-id>.r2.cloudflarestorage.com
# AWS S3: https://s3.us-east-1.amazonaws.com
S3__ENDPOINT=https://oss-cn-hangzhou.aliyuncs.com

# S3 è®¿é—®å¯†é’¥ ID
S3__ACCESS_KEY_ID=your_access_key

# S3 è®¿é—®å¯†é’¥
S3__SECRET_ACCESS_KEY=your_secret_key

# S3 å­˜å‚¨æ¡¶åç§°
S3__BUCKET=your_bucket_name

# S3 å¯¹è±¡é”®å‰ç¼€ï¼ˆå¯é€‰ï¼‰
S3__PREFIX=

# S3 åŒºåŸŸ
S3__REGION=cn-hangzhou


# ==================== æ–‡ä»¶å­˜å‚¨é…ç½® ====================
# ä¸Šä¼ æ–‡ä»¶ç›®å½•
FILE_STORAGE__UPLOAD_DIR=/data/uploads

# æŠ¥å‘Šæ–‡ä»¶ç›®å½•
FILE_STORAGE__REPORT_DIR=/data/reports

# ä¸´æ—¶æ–‡ä»¶ç›®å½•
FILE_STORAGE__TEMP_DIR=/tmp


# ==================== ä½¿ç”¨è¯´æ˜ ====================
# 1. å¤åˆ¶æ­¤æ–‡ä»¶ä¸º .env.development æˆ– .env.production
# 2. æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹é…ç½®å€¼
# 3. ä¸éœ€è¦çš„é…ç½®å¯ä»¥æ³¨é‡Šæ‰æˆ–åˆ é™¤
# 4. æ•æ„Ÿä¿¡æ¯ï¼ˆå¯†ç ã€å¯†é’¥ï¼‰ä¸è¦æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶
# 5. ç”Ÿäº§ç¯å¢ƒå¿…é¡»ä½¿ç”¨å¼ºéšæœºå€¼ä½œä¸ºå¯†é’¥
```

## äº‘æ•ˆéƒ¨ç½²é…ç½®

### ç¯å¢ƒå˜é‡æ³¨å…¥ç­–ç•¥
åœ¨é˜¿é‡Œäº‘æ•ˆä¸­ï¼Œé€šè¿‡æ„å»ºç¯å¢ƒå˜é‡æ³¨å…¥ç”Ÿäº§é…ç½®ï¼š

```yaml
# äº‘æ•ˆ Pipeline ç¯å¢ƒå˜é‡é…ç½®
environment:
  ENV: production
  DEBUG: "false"
  
  # æ•°æ®åº“é…ç½®ï¼ˆä½¿ç”¨ DATABASE__ å‰ç¼€ï¼‰
  DATABASE__USER: ${DB_USER}
  DATABASE__PASSWORD: ${DB_PASSWORD}
  DATABASE__HOST: ${DB_HOST}
  DATABASE__PORT: "5432"
  DATABASE__NAME: ${DB_NAME}
  DATABASE__ECHO_LOG: "false"
  
  # NATS é…ç½®ï¼ˆä½¿ç”¨ NATS__ å‰ç¼€ï¼Œæ”¯æŒåˆ«åï¼‰
  NATS_SERVER_URL: ${NATS_URL}  # ä½¿ç”¨åˆ«åæ˜ å°„åˆ° NATS__URL
  NATS__STREAM: ${NATS_STREAM}
  
  # S3 é…ç½®ï¼ˆä½¿ç”¨ S3__ å‰ç¼€ï¼‰
  S3__ENDPOINT: ${OSS_ENDPOINT}
  S3__ACCESS_KEY_ID: ${OSS_ACCESS_KEY}
  S3__SECRET_ACCESS_KEY: ${OSS_SECRET_KEY}
  S3__BUCKET: ${OSS_BUCKET}
  S3__REGION: ${OSS_REGION}
  
  # æ–‡ä»¶å­˜å‚¨é…ç½®ï¼ˆä½¿ç”¨ FILE_STORAGE__ å‰ç¼€ï¼‰
  FILE_STORAGE__UPLOAD_DIR: /data/uploads
  FILE_STORAGE__TEMP_DIR: /tmp
```

### Docker ç¯å¢ƒå˜é‡ä¼ é€’
```dockerfile
# Dockerfile ä¸­æ”¯æŒç¯å¢ƒå˜é‡
ENV ENV=production
ENV DEBUG=false
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# è¿è¡Œæ—¶ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
CMD ["pdm", "run", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Docker Compose ç¯å¢ƒå˜é‡
```yaml
# docker-compose.prod.yml
services:
  app:
    environment:
      - ENV=production
      - DEBUG=false
      # æ•°æ®åº“é…ç½®
      - DATABASE__USER=${DB_USER}
      - DATABASE__PASSWORD=${DB_PASSWORD}
      - DATABASE__HOST=postgres
      - DATABASE__PORT=5432
      - DATABASE__NAME=${DB_NAME}
      # NATS é…ç½®
      - NATS__URL=nats://nats:4222
      - NATS__STREAM=taskiq
      # æ–‡ä»¶å­˜å‚¨é…ç½®
      - FILE_STORAGE__TEMP_DIR=/tmp
    env_file:
      - .env.production  # å¯é€‰çš„ç¯å¢ƒæ–‡ä»¶
```

## é…ç½®éªŒè¯å’Œè°ƒè¯•

### å¼€å‘ç¯å¢ƒé…ç½®æ£€æŸ¥
```python
# ä»…åœ¨å¼€å‘ç¯å¢ƒæ˜¾ç¤ºæ•æ„Ÿä¿¡æ¯
if settings.env == Environment.DEVELOPMENT:
    logger.info(f"ğŸš€ è¿è¡Œç¯å¢ƒ: {settings.env.value}")
    logger.info(f"ğŸ› è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if settings.debug else 'å…³é—­'}")
    logger.info(f"ğŸ—„ï¸  æ•°æ®åº“: {settings.database.host}:{settings.database.port}/{settings.database.name}")
    logger.info(f"ğŸ“¨ NATS: {settings.nats.url} (stream: {settings.nats.stream})")
    logger.info(f"ğŸ“ ä¸´æ—¶ç›®å½•: {settings.file_storage.temp_dir}")
```

### é…ç½®è®¿é—®æ–¹å¼
```python
# è®¿é—®åµŒå¥—é…ç½®
database_url = settings.database.async_url
nats_servers = settings.nats.servers
s3_endpoint = settings.s3.endpoint
temp_dir = settings.file_storage.temp_uploads_dir

# ä½¿ç”¨é…ç½®å±æ€§
async with create_async_engine(settings.database.async_url) as engine:
    # ...
```

### é…ç½®æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
```python
def validate_config_files():
    """éªŒè¯é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    env = os.getenv("ENV", "development").lower()
    specific_env_file = ROOT_DIR / f".env.{env}"
    default_env_file = ROOT_DIR / ".env"
    
    if not specific_env_file.exists() and not default_env_file.exists():
        logger.warning("âš ï¸  æœªæ‰¾åˆ° .env æ–‡ä»¶ï¼Œä»…ä½¿ç”¨ç¯å¢ƒå˜é‡")
    else:
        config_source = specific_env_file if specific_env_file.exists() else default_env_file
        logger.info(f"âœ… é…ç½®åŠ è½½è‡ª: {config_source}")
```

## å®‰å…¨æœ€ä½³å®è·µ

### æ•æ„Ÿä¿¡æ¯å¤„ç†
- âœ… **ç”Ÿäº§ç¯å¢ƒ**: ä½¿ç”¨äº‘æ•ˆç¯å¢ƒå˜é‡æ³¨å…¥
- âœ… **å¼€å‘ç¯å¢ƒ**: ä½¿ç”¨ `.env.development` æ–‡ä»¶
- âŒ **ç¦æ­¢**: åœ¨ä»£ç ä¸­ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯
- âŒ **ç¦æ­¢**: å°† `.env.*` æ–‡ä»¶æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶

### .gitignore é…ç½®
```gitignore
# ç¯å¢ƒé…ç½®æ–‡ä»¶
.env
.env.*
!.env.example  # æ¨¡æ¿æ–‡ä»¶å¯ä»¥æäº¤
```

### é…ç½®å­—æ®µç±»å‹å®‰å…¨
```python
# ä½¿ç”¨ Pydantic ç±»å‹éªŒè¯å’ŒåµŒå¥—é…ç½®
class DatabaseConfig(BaseModel):
    port: int = 5432  # è‡ªåŠ¨ç±»å‹è½¬æ¢
    echo_log: bool = False  # å¸ƒå°”å€¼éªŒè¯
    pool_size: int = Field(default=10, description="è¿æ¥æ± å¤§å°")
    
    # å¯é€‰å­—æ®µä½¿ç”¨ | None ç±»å‹
    user: str | None = None
    password: str | None = None

class NATSConfig(BaseModel):
    url: str = Field(default="nats://localhost:4222")
    stream: str = Field(default="taskiq")
    user: str | None = None  # å¯é€‰å­—æ®µ
    password: str | None = None  # å¯é€‰å­—æ®µ

class Settings(BaseSettings):
    env: Environment = Environment.DEVELOPMENT
    debug: bool = False
    
    # åµŒå¥—é…ç½®ï¼ˆå¿…å¡«ï¼‰
    database: DatabaseConfig
    nats: NATSConfig
    
    # åµŒå¥—é…ç½®ï¼ˆå¯é€‰ï¼‰
    s3: S3Config | None = None
```

## å¤šç¯å¢ƒç®¡ç†

### ç¯å¢ƒåˆ‡æ¢
```bash
# æœ¬åœ°å¼€å‘
ENV=development pdm run uvicorn main:app --reload

# æµ‹è¯•ç¯å¢ƒ
ENV=testing pdm run pytest

# ç”Ÿäº§ç¯å¢ƒ (é€šè¿‡äº‘æ•ˆè‡ªåŠ¨è®¾ç½®)
ENV=production
```

### ç¯å¢ƒç‰¹å®šé…ç½®
```python
# æ ¹æ®ç¯å¢ƒè°ƒæ•´è¡Œä¸º
if settings.env == Environment.DEVELOPMENT:
    # å¼€å‘ç¯å¢ƒç‰¹å®šé…ç½®
    app.add_middleware(CORSMiddleware, allow_origins=["*"])
    
    # å¼€å¯ SQL æ—¥å¿—
    engine = create_async_engine(
        settings.database.async_url,
        echo=settings.database.echo_log
    )
    
elif settings.env == Environment.PRODUCTION:
    # ç”Ÿäº§ç¯å¢ƒç‰¹å®šé…ç½®
    app.add_middleware(CORSMiddleware, allow_origins=["https://yourdomain.com"])
    
    # å…³é—­ SQL æ—¥å¿—
    engine = create_async_engine(
        settings.database.async_url,
        echo=False,
        pool_size=settings.database.pool_size,
        max_overflow=settings.database.max_overflow
    )
```

### é…ç½®ç»„åˆä½¿ç”¨ç¤ºä¾‹
```python
# æ•°æ®åº“è¿æ¥
from sqlalchemy.ext.asyncio import create_async_engine

engine = create_async_engine(
    settings.database.async_url,
    echo=settings.database.echo_log,
    pool_size=settings.database.pool_size,
    max_overflow=settings.database.max_overflow
)

# NATS è¿æ¥
from taskiq_nats import NatsBroker

broker = NatsBroker(
    servers=settings.nats.servers,
    stream_name=settings.nats.stream,
    queue="workers"
)

# S3 å®¢æˆ·ç«¯
import boto3

if settings.s3.endpoint:
    s3_client = boto3.client(
        's3',
        endpoint_url=settings.s3.endpoint,
        aws_access_key_id=settings.s3.access_key_id,
        aws_secret_access_key=settings.s3.secret_access_key,
        region_name=settings.s3.region
    )
```